{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samson\\AppData\\Local\\Continuum\\anaconda2\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setting - char matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "filename = \"haikus.txt\"\n",
    "raw_text = io.open(filename, encoding='utf-8').read()\n",
    "text = raw_text.lower()\n",
    "chars = list(set(raw_text))\n",
    "chars.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fishing boats\n",
      "colors of\n",
      "the rainbow\n",
      "\n",
      "ash wednesday\n",
      "trying to remember\n",
      "my dream\n",
      "\n",
      "japanese quake\n",
      "this godless spring\n",
      "tsunami\n",
      "\n",
      "snowy morn\n",
      "pouring another cup\n",
      "of black coffee\n",
      "\n",
      "shortest day\n",
      "flames dance\n",
      "in the oven\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (text[:210])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of sequences: 224544\n"
     ]
    }
   ],
   "source": [
    "maxlen = 20\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen]) #get sentences of 20 characters as X\n",
    "    next_chars.append(text[i + maxlen]) #get the next char after the sentence as y\n",
    "print('no. of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ats colors of the ra\n",
      "ts colors of the rai\n",
      "s colors of the rain\n",
      " colors of the rainb\n",
      "colors of the rainbo\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences[10:15]:\n",
    "    print (sentence.replace('\\n',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "n\n",
      "b\n",
      "o\n",
      "w\n"
     ]
    }
   ],
   "source": [
    "for i in next_chars[10:15]:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: fishing boats\n",
      "colors\n",
      "next char:  \n",
      "sentence: ishing boats\n",
      "colors \n",
      "next char: o\n",
      "sentence: shing boats\n",
      "colors o\n",
      "next char: f\n",
      "sentence: hing boats\n",
      "colors of\n",
      "next char: \n",
      "\n",
      "sentence: ing boats\n",
      "colors of\n",
      "\n",
      "next char: t\n"
     ]
    }
   ],
   "source": [
    "#example of sentences & next chars\n",
    "for i in range(5):\n",
    "    print ('sentence:', sentences[i])\n",
    "    print ('next char:', next_chars[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224544, 20, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizing into matrix - one hot encoding of the characters\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool) #encode each sentence with maxlen of 20 and character of 38 - shape(len(sentences), 20, 38)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setting GRU arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 20, 512)           886272    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 512)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               590592    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 1,493,312\n",
      "Trainable params: 1,493,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(512,  input_shape=(maxlen,len(chars)), return_sequences=True))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "# model.add(LSTM(512, return_sequences=True))\n",
    "# model.add(Dropout(0.20))\n",
    "\n",
    "#model.add(LSTM(512, return_sequences=True))\n",
    "#model.add(Dropout(0.20))\n",
    "\n",
    "model.add(GRU(256, return_sequences=False))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.summary()\n",
    "# compile or load weights then compile depending\n",
    "\n",
    "#the total number of parameters in the GRU RNN equals 3Ã—(n2+nm+n).\n",
    "#where m is the input dimension and n is the output dimension. This is due to the fact that there are three sets of operations requiring weight matrices of these sizes.\n",
    "#https://arxiv.org/ftp/arxiv/papers/1701/1701.05923.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X, y, batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model to file\n",
    "# model.save('drive/haiku_10.h5')\n",
    "\n",
    "# from pickle import dump\n",
    "# # save the mapping\n",
    "# dump(char_indices, open('drive/mapping_10.pkl', 'wb'))\n",
    "# #https://machinelearningmastery.com/develop-character-based-neural-language-model-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#https://machinelearningmastery.com/develop-character-based-neural-language-model-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('haiku_30.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mapping\n",
    "mapping = load(open('mapping.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    a = np.log(a) / temperature \n",
    "    dist = np.exp(a)/np.sum(np.exp(a)) \n",
    "    choices = range(len(a)) \n",
    "    return np.random.choice(choices, p=dist)#random.choices to implement weighted random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, sys\n",
    "def generate_from_model(model):\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1) #initiate random character from text sequence\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]: #diversity to feed temperature to pick random probabilities for char pred\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index : start_index + maxlen] #take a sentence of 20 char from the random start_index char\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        tot_lines = 0 #count lines for break >3\n",
    "        tot_chars = 0 #count chars for break >120\n",
    "\n",
    "        while True:\n",
    "            if tot_lines > 3 or tot_chars > 120:\n",
    "                break\n",
    "            x = np.zeros((1, maxlen, len(mapping))) #create empty input\n",
    "            for t, char in enumerate(sentence): \n",
    "                x[0, t, char_indices[char]] = 1. #one-hot encode sample sentence\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0] #predict [0] as output is in matrix\n",
    "            next_index = sample(preds, diversity) #diversity allows picking of prob < max. smaller diversity uses higher prob\n",
    "            next_char = indices_char[next_index] #retrieve char from selected index\n",
    "\n",
    "            tot_chars += 1\n",
    "            generated += next_char\n",
    "            if next_char == '\\n':\n",
    "                tot_lines += 1\n",
    "            sentence = sentence[1:] + next_char #add next_char to sentence for while loop to predict next char, start from 1 to maintain maxlen\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"stove\n",
      "november morni\"\n",
      "stove\n",
      "november morning\n",
      "\n",
      "sunset and stare\n",
      "a flag cerepart back\n",
      "\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"stove\n",
      "november morni\"\n",
      "stove\n",
      "november morning\n",
      "\n",
      "santaso day\n",
      "my wife buddhason silence\n",
      "\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"stove\n",
      "november morni\"\n",
      "stove\n",
      "november morning\n",
      "\n",
      "somewhere\n",
      "into traffic\n",
      "\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"stove\n",
      "november morni\"\n",
      "stove\n",
      "november morning\n",
      "\n",
      "rahmailed chusid\n",
      "a snow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model)#30 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Productionising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from pickle import load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model = load_model('haiku_30.h5')\n",
    "# load the mapping\n",
    "mapping = load(open('mapping.pkl', 'rb'))\n",
    "inv_map = {v: k for k, v in mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temperature to prevent selection of top prob\n",
    "def sample(a, temperature=1.0):\n",
    "    a = np.log(a) / temperature \n",
    "    dist = np.exp(a)/np.sum(np.exp(a)) \n",
    "    choices = range(len(a)) \n",
    "    return np.random.choice(choices, p=dist)#random.choices to implement weighted random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spell correct\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from autocorrect import spell\n",
    "def cleaning(sentence):\n",
    "    tokenizer_words = TweetTokenizer()\n",
    "    spellcheck = []\n",
    "    for word in tokenizer_words.tokenize(sentence):\n",
    "        if word not in [',','!','.',':']:\n",
    "            spellcheck.append(spell(word))\n",
    "        else:\n",
    "            spellcheck.append(word)\n",
    "    corr_sent = ' '.join(spellcheck)\n",
    "    return corr_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your input is: hello morning star\n",
      "  hello morning start\n",
      "\n",
      "soft rain\n",
      "butterflies butterfly\n",
      "\n",
      "hello morning start\n",
      "soft rain\n",
      "butterflies butterfly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usr_input = input(\"Your input is: \")\n",
    "usr_input = re.sub('[^a-zA-Z0-9 \\n\\.]', '', usr_input).lower()\n",
    "sentence = ('{:>' + str(20) + '}').format(usr_input[:20]).lower()\n",
    "generated = ''\n",
    "generated += sentence\n",
    "sys.stdout.write(generated)\n",
    "tot_lines = 0\n",
    "tot_chars = 0\n",
    "while True:\n",
    "        if tot_lines > 3 or tot_chars > 120:\n",
    "            break\n",
    "        x = np.zeros((1, 20, len(mapping)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, mapping[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, 0.5)\n",
    "        next_char = inv_map[next_index]\n",
    "\n",
    "        tot_chars += 1\n",
    "        generated += next_char\n",
    "        if next_char == '\\n':\n",
    "            tot_lines += 1\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "print ('')\n",
    "gen = generated.replace('\\n\\n','\\n')\n",
    "gen = gen.split('\\n')\n",
    "clean_gen = []\n",
    "for i in gen:\n",
    "    clean_gen.append(cleaning(i))\n",
    "clean_gen = '\\n'.join(clean_gen)\n",
    "print (clean_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pect the job\\n\\njust f'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pect the job<br><br>just f'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.replace('\\n','<br>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate for human/bot test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "late june crowded\n",
      "to the reading tonight\n",
      "moonless night\n",
      "\n",
      "\n",
      "monday morning\n",
      "a birthday silence\n",
      "become statues\n",
      "\n",
      "\n",
      "reflections\n",
      "open window\n",
      "\n",
      "\n",
      "another birthday\n",
      "white curser reses\n",
      "\n",
      "\n",
      "between the temple\n",
      "monday morning\n",
      "a blue plastic bag\n",
      "\n",
      "\n",
      "autumn child\n",
      "find lights up a slipping in the highway\n",
      "\n",
      "\n",
      "lily dust pause on a cloud\n",
      "a drifting dusk silence\n",
      "the stone buddha\n",
      "\n",
      "\n",
      "carved on the closed rest\n",
      "to crows ward\n",
      "first fireflies chicken\n",
      "\n",
      "\n",
      "a skein of birds\n",
      "twines only the time\n",
      "Silenales changed\n",
      "a spring morning\n",
      "\n",
      "\n",
      "kitchen afternoon\n",
      "the first light on in the sky\n",
      "the new year\n",
      "a blind man starts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1) #initiate random character from text sequence\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index : start_index + maxlen] #take a sentence of 20 char from the random start_index char\n",
    "    generated += sentence\n",
    "\n",
    "    # sys.stdout.write(generated)\n",
    "    tot_lines = 0\n",
    "    tot_chars = 0\n",
    "    while True:\n",
    "            if tot_lines > 3 or tot_chars > 120:\n",
    "                break\n",
    "            x = np.zeros((1, 20, len(mapping)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, mapping[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, 0.5)\n",
    "            next_char = inv_map[next_index]\n",
    "\n",
    "            tot_chars += 1\n",
    "            generated += next_char\n",
    "            if next_char == '\\n':\n",
    "                tot_lines += 1\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "    #         sys.stdout.write(next_char)\n",
    "    #         sys.stdout.flush()\n",
    "    print ('')\n",
    "    gen = generated.replace('\\n\\n','\\n')\n",
    "    gen = gen.split('\\n')\n",
    "    clean_gen = []\n",
    "    for i in gen:\n",
    "        clean_gen.append(cleaning(i))\n",
    "    clean_gen = '\\n'.join(clean_gen[1:]) #remove first set of inputs due to incompleteness\n",
    "    print (clean_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ed laundry kitchen afternoon the first light on in the sky the new year a blind man starts'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
